{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from copy import copy, deepcopy\n",
    "\n",
    "seed_value = 99999\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "from numpy.random import seed\n",
    "seed(seed_value)\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.random.set_random_seed(seed_value)\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import ElasticNet,ElasticNetCV,Ridge,Lasso,LinearRegression,MultiTaskLasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "calib_dir = 'C:/kitti/training/calib/'\n",
    "label_2_dir = 'C:/kitti/training/label_2/'\n",
    "label_2_testing_dir = 'C:/kitti/testing/label_2/'\n",
    "label_3_dir = 'C:/kitti/training/label_3/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Calibration(object):\n",
    "    \"\"\" Calibration matrices and utils\n",
    "        3d XYZ in <label>.txt are in rect camera coord.\n",
    "        2d box xy are in image2 coord\n",
    "        Points in <lidar>.bin are in Velodyne coord.\n",
    "\n",
    "        y_image2 = P^2_rect * x_rect\n",
    "        y_image2 = P^2_rect * R0_rect * Tr_velo_to_cam * x_velo\n",
    "        x_ref = Tr_velo_to_cam * x_velo\n",
    "        x_rect = R0_rect * x_ref\n",
    "\n",
    "        P^2_rect = [f^2_u,  0,      c^2_u,  -f^2_u b^2_x;\n",
    "                    0,      f^2_v,  c^2_v,  -f^2_v b^2_y;\n",
    "                    0,      0,      1,      0]\n",
    "                 = K * [1|t]\n",
    "\n",
    "        image2 coord:\n",
    "         ----> x-axis (u)\n",
    "        |\n",
    "        |\n",
    "        v y-axis (v)\n",
    "\n",
    "        velodyne coord:\n",
    "        front x, left y, up z\n",
    "\n",
    "        rect/ref camera coord:\n",
    "        right x, down y, front z\n",
    "\n",
    "        Ref (KITTI paper): http://www.cvlibs.net/publications/Geiger2013IJRR.pdf\n",
    "\n",
    "        TODO(rqi): do matrix multiplication only once for each projection.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, calib_filepath, from_video=False):\n",
    "        if from_video:\n",
    "            calibs = self.read_calib_from_video(calib_filepath)\n",
    "        else:\n",
    "            calibs = self.read_calib_file(calib_filepath)\n",
    "        # Projection matrix from rect camera coord to image2 coord\n",
    "        self.P = calibs[\"P2\"]\n",
    "        self.P3 = calibs[\"P3\"]\n",
    "        self.P = np.reshape(self.P, [3, 4])\n",
    "        self.P3 = np.reshape(self.P3, [3, 4])\n",
    "        # Rigid transform from Velodyne coord to reference camera coord\n",
    "        self.V2C = calibs[\"Tr_velo_to_cam\"]\n",
    "        self.V2C = np.reshape(self.V2C, [3, 4])\n",
    "        self.C2V = inverse_rigid_trans(self.V2C)\n",
    "        # Rotation from reference camera coord to rect camera coord\n",
    "        self.R0 = calibs[\"R0_rect\"]\n",
    "        self.R0 = np.reshape(self.R0, [3, 3])\n",
    "\n",
    "        # Camera intrinsics and extrinsics\n",
    "        self.c_u = self.P[0, 2]\n",
    "        self.c_v = self.P[1, 2]\n",
    "        self.f_u = self.P[0, 0]\n",
    "        self.f_v = self.P[1, 1]\n",
    "        self.b_x = self.P[0, 3] / (-self.f_u)  # relative\n",
    "        self.b_y = self.P[1, 3] / (-self.f_v)\n",
    "\n",
    "    def read_calib_file(self, filepath):\n",
    "        \"\"\" Read in a calibration file and parse into a dictionary.\n",
    "        Ref: https://github.com/utiasSTARS/pykitti/blob/master/pykitti/utils.py\n",
    "        \"\"\"\n",
    "        data = {}\n",
    "        with open(filepath, \"r\") as f:\n",
    "            for line in f.readlines():\n",
    "                line = line.rstrip()\n",
    "                if len(line) == 0:\n",
    "                    continue\n",
    "                key, value = line.split(\":\", 1)\n",
    "                # The only non-float values in these files are dates, which\n",
    "                # we don't care about anyway\n",
    "                try:\n",
    "                    data[key] = np.array([float(x) for x in value.split()])\n",
    "                except ValueError:\n",
    "                    pass\n",
    "\n",
    "        return data\n",
    "\n",
    "    def read_calib_from_video(self, calib_root_dir):\n",
    "        \"\"\" Read calibration for camera 2 from video calib files.\n",
    "            there are calib_cam_to_cam and calib_velo_to_cam under the calib_root_dir\n",
    "        \"\"\"\n",
    "        data = {}\n",
    "        cam2cam = self.read_calib_file(\n",
    "            os.path.join(calib_root_dir, \"calib_cam_to_cam.txt\")\n",
    "        )\n",
    "        velo2cam = self.read_calib_file(\n",
    "            os.path.join(calib_root_dir, \"calib_velo_to_cam.txt\")\n",
    "        )\n",
    "        Tr_velo_to_cam = np.zeros((3, 4))\n",
    "        Tr_velo_to_cam[0:3, 0:3] = np.reshape(velo2cam[\"R\"], [3, 3])\n",
    "        Tr_velo_to_cam[:, 3] = velo2cam[\"T\"]\n",
    "        data[\"Tr_velo_to_cam\"] = np.reshape(Tr_velo_to_cam, [12])\n",
    "        data[\"R0_rect\"] = cam2cam[\"R_rect_00\"]\n",
    "        data[\"P2\"] = cam2cam[\"P_rect_02\"]\n",
    "        return data\n",
    "\n",
    "    def cart2hom(self, pts_3d):\n",
    "        \"\"\" Input: nx3 points in Cartesian\n",
    "            Oupput: nx4 points in Homogeneous by pending 1\n",
    "        \"\"\"\n",
    "        n = pts_3d.shape[0]\n",
    "        pts_3d_hom = np.hstack((pts_3d, np.ones((n, 1))))\n",
    "        return pts_3d_hom\n",
    "\n",
    "    # ===========================\n",
    "    # ------- 3d to 3d ----------\n",
    "    # ===========================\n",
    "    def project_velo_to_ref(self, pts_3d_velo):\n",
    "        pts_3d_velo = self.cart2hom(pts_3d_velo)  # nx4\n",
    "        return np.dot(pts_3d_velo, np.transpose(self.V2C))\n",
    "\n",
    "    def project_ref_to_velo(self, pts_3d_ref):\n",
    "        pts_3d_ref = self.cart2hom(pts_3d_ref)  # nx4\n",
    "        return np.dot(pts_3d_ref, np.transpose(self.C2V))\n",
    "\n",
    "    def project_rect_to_ref(self, pts_3d_rect):\n",
    "        \"\"\" Input and Output are nx3 points \"\"\"\n",
    "        return np.transpose(np.dot(np.linalg.inv(self.R0), np.transpose(pts_3d_rect)))\n",
    "\n",
    "    def project_ref_to_rect(self, pts_3d_ref):\n",
    "        \"\"\" Input and Output are nx3 points \"\"\"\n",
    "        return np.transpose(np.dot(self.R0, np.transpose(pts_3d_ref)))\n",
    "\n",
    "    def project_rect_to_velo(self, pts_3d_rect):\n",
    "        \"\"\" Input: nx3 points in rect camera coord.\n",
    "            Output: nx3 points in velodyne coord.\n",
    "        \"\"\"\n",
    "        pts_3d_ref = self.project_rect_to_ref(pts_3d_rect)\n",
    "        return self.project_ref_to_velo(pts_3d_ref)\n",
    "\n",
    "    def project_velo_to_rect(self, pts_3d_velo):\n",
    "        pts_3d_ref = self.project_velo_to_ref(pts_3d_velo)\n",
    "        return self.project_ref_to_rect(pts_3d_ref)\n",
    "\n",
    "    # ===========================\n",
    "    # ------- 3d to 2d ----------\n",
    "    # ===========================\n",
    "    def project_rect_to_image(self, pts_3d_rect):\n",
    "        \"\"\" Input: nx3 points in rect camera coord.\n",
    "            Output: nx2 points in image2 coord.\n",
    "        \"\"\"\n",
    "        pts_3d_rect = self.cart2hom(pts_3d_rect)\n",
    "        pts_2d = np.dot(pts_3d_rect, np.transpose(self.P))  # nx3\n",
    "        pts_2d[:, 0] /= pts_2d[:, 2]\n",
    "        pts_2d[:, 1] /= pts_2d[:, 2]\n",
    "        return pts_2d[:, 0:2]\n",
    "\n",
    "    def project_rect_to_image_3(self, pts_3d_rect):\n",
    "        \"\"\" Input: nx3 points in rect camera coord.\n",
    "            Output: nx2 points in image2 coord.\n",
    "        \"\"\"\n",
    "        pts_3d_rect = self.cart2hom(pts_3d_rect)\n",
    "        pts_2d = np.dot(pts_3d_rect, np.transpose(self.P3))  # nx3\n",
    "        pts_2d[:, 0] /= pts_2d[:, 2]\n",
    "        pts_2d[:, 1] /= pts_2d[:, 2]\n",
    "        return pts_2d[:, 0:2]\n",
    "\n",
    "    def project_velo_to_image(self, pts_3d_velo):\n",
    "        \"\"\" Input: nx3 points in velodyne coord.\n",
    "            Output: nx2 points in image2 coord.\n",
    "        \"\"\"\n",
    "        pts_3d_rect = self.project_velo_to_rect(pts_3d_velo)\n",
    "        return self.project_rect_to_image(pts_3d_rect)\n",
    "\n",
    "    def project_8p_to_4p(self, pts_2d):\n",
    "        x0 = np.min(pts_2d[:, 0])\n",
    "        x1 = np.max(pts_2d[:, 0])\n",
    "        y0 = np.min(pts_2d[:, 1])\n",
    "        y1 = np.max(pts_2d[:, 1])\n",
    "        x0 = max(0, x0)\n",
    "        # x1 = min(x1, proj.image_width)\n",
    "        y0 = max(0, y0)\n",
    "        # y1 = min(y1, proj.image_height)\n",
    "        return np.array([x0, y0, x1, y1])\n",
    "\n",
    "    def project_velo_to_4p(self, pts_3d_velo):\n",
    "        \"\"\" Input: nx3 points in velodyne coord.\n",
    "            Output: 4 points in image2 coord.\n",
    "        \"\"\"\n",
    "        pts_2d_velo = self.project_velo_to_image(pts_3d_velo)\n",
    "        return self.project_8p_to_4p(pts_2d_velo)\n",
    "\n",
    "    # ===========================\n",
    "    # ------- 2d to 3d ----------\n",
    "    # ===========================\n",
    "    def project_image_to_rect(self, uv_depth):\n",
    "        \"\"\" Input: nx3 first two channels are uv, 3rd channel\n",
    "                   is depth in rect camera coord.\n",
    "            Output: nx3 points in rect camera coord.\n",
    "        \"\"\"\n",
    "        n = uv_depth.shape[0]\n",
    "        x = ((uv_depth[:, 0] - self.c_u) * uv_depth[:, 2]) / self.f_u + self.b_x\n",
    "        y = ((uv_depth[:, 1] - self.c_v) * uv_depth[:, 2]) / self.f_v + self.b_y\n",
    "        pts_3d_rect = np.zeros((n, 3))\n",
    "        pts_3d_rect[:, 0] = x\n",
    "        pts_3d_rect[:, 1] = y\n",
    "        pts_3d_rect[:, 2] = uv_depth[:, 2]\n",
    "        return pts_3d_rect\n",
    "\n",
    "    def project_image_to_velo(self, uv_depth):\n",
    "        pts_3d_rect = self.project_image_to_rect(uv_depth)\n",
    "        return self.project_rect_to_velo(pts_3d_rect)\n",
    "\n",
    "    def project_depth_to_velo(self, depth, constraint_box=True):\n",
    "        depth_pt3d = get_depth_pt3d(depth)\n",
    "        depth_UVDepth = np.zeros_like(depth_pt3d)\n",
    "        depth_UVDepth[:, 0] = depth_pt3d[:, 1]\n",
    "        depth_UVDepth[:, 1] = depth_pt3d[:, 0]\n",
    "        depth_UVDepth[:, 2] = depth_pt3d[:, 2]\n",
    "        # print(\"depth_pt3d:\",depth_UVDepth.shape)\n",
    "        depth_pc_velo = self.project_image_to_velo(depth_UVDepth)\n",
    "        # print(\"dep_pc_velo:\",depth_pc_velo.shape)\n",
    "        if constraint_box:\n",
    "            depth_box_fov_inds = (\n",
    "                (depth_pc_velo[:, 0] < cbox[0][1])\n",
    "                & (depth_pc_velo[:, 0] >= cbox[0][0])\n",
    "                & (depth_pc_velo[:, 1] < cbox[1][1])\n",
    "                & (depth_pc_velo[:, 1] >= cbox[1][0])\n",
    "                & (depth_pc_velo[:, 2] < cbox[2][1])\n",
    "                & (depth_pc_velo[:, 2] >= cbox[2][0])\n",
    "            )\n",
    "            depth_pc_velo = depth_pc_velo[depth_box_fov_inds]\n",
    "        return depth_pc_velo\n",
    "        \n",
    "class Object3d(object):\n",
    "    \"\"\" 3d object label \"\"\"\n",
    "\n",
    "    def __init__(self, label_file_line):\n",
    "        data = label_file_line.split(\" \")\n",
    "        data[1:] = [float(x) for x in data[1:]]\n",
    "\n",
    "        # extract label, truncation, occlusion\n",
    "        self.type = data[0]  # 'Car', 'Pedestrian', ...\n",
    "        self.truncation = data[1]  # truncated pixel ratio [0..1]\n",
    "        self.occlusion = int(\n",
    "            data[2]\n",
    "        )  # 0=visible, 1=partly occluded, 2=fully occluded, 3=unknown\n",
    "        self.alpha = data[3]  # object observation angle [-pi..pi]\n",
    "\n",
    "        # extract 2d bounding box in 0-based coordinates\n",
    "        self.xmin = data[4]  # left\n",
    "        self.ymin = data[5]  # top\n",
    "        self.xmax = data[6]  # right\n",
    "        self.ymax = data[7]  # bottom\n",
    "        self.box2d = np.array([self.xmin, self.ymin, self.xmax, self.ymax])\n",
    "\n",
    "        # extract 3d bounding box information\n",
    "        self.h = data[8]  # box height\n",
    "        self.w = data[9]  # box width\n",
    "        self.l = data[10]  # box length (in meters)\n",
    "        self.t = (data[11], data[12], data[13])  # location (x,y,z) in camera coord.\n",
    "        self.ry = data[14]  # yaw angle (around Y-axis in camera coordinates) [-pi..pi]\n",
    "\n",
    "    def estimate_diffculty(self):\n",
    "        \"\"\" Function that estimate difficulty to detect the object as defined in kitti website\"\"\"\n",
    "        # height of the bounding box\n",
    "        bb_height = np.abs(self.xmax - self.xmin)\n",
    "\n",
    "        if bb_height >= 40 and self.occlusion == 0 and self.truncation <= 0.15:\n",
    "            return \"Easy\"\n",
    "        elif bb_height >= 25 and self.occlusion in [0, 1] and self.truncation <= 0.30:\n",
    "            return \"Moderate\"\n",
    "        elif (\n",
    "            bb_height >= 25 and self.occlusion in [0, 1, 2] and self.truncation <= 0.50\n",
    "        ):\n",
    "            return \"Hard\"\n",
    "        else:\n",
    "            return \"Unknown\"\n",
    "\n",
    "    def print_object(self):\n",
    "        print(\n",
    "            \"Type, truncation, occlusion, alpha: %s, %d, %d, %f\"\n",
    "            % (self.type, self.truncation, self.occlusion, self.alpha)\n",
    "        )\n",
    "        print(\n",
    "            \"2d bbox (x0,y0,x1,y1): %f, %f, %f, %f\"\n",
    "            % (self.xmin, self.ymin, self.xmax, self.ymax)\n",
    "        )\n",
    "        print(\"3d bbox h,w,l: %f, %f, %f\" % (self.h, self.w, self.l))\n",
    "        print(\n",
    "            \"3d bbox location, ry: (%f, %f, %f), %f\"\n",
    "            % (self.t[0], self.t[1], self.t[2], self.ry)\n",
    "        )\n",
    "        print(\"Difficulty of estimation: {}\".format(self.estimate_diffculty()))\n",
    "\n",
    "def compute_box_3d(obj, P):\n",
    "    \"\"\" Takes an object and a projection matrix (P) and projects the 3d\n",
    "        bounding box into the image plane.\n",
    "        Returns:\n",
    "            corners_2d: (8,2) array in left image coord.\n",
    "            corners_3d: (8,3) array in in rect camera coord.\n",
    "    \"\"\"\n",
    "    # compute rotational matrix around yaw axis\n",
    "    R = roty(obj.ry)\n",
    "\n",
    "    # 3d bounding box dimensions\n",
    "    l = obj.l\n",
    "    w = obj.w\n",
    "    h = obj.h\n",
    "\n",
    "    # 3d bounding box corners\n",
    "    x_corners = [l / 2, l / 2, -l / 2, -l / 2, l / 2, l / 2, -l / 2, -l / 2]\n",
    "    y_corners = [0, 0, 0, 0, -h, -h, -h, -h]\n",
    "    z_corners = [w / 2, -w / 2, -w / 2, w / 2, w / 2, -w / 2, -w / 2, w / 2]\n",
    "\n",
    "    # rotate and translate 3d bounding box\n",
    "    corners_3d = np.dot(R, np.vstack([x_corners, y_corners, z_corners]))\n",
    "    # print corners_3d.shape\n",
    "    corners_3d[0, :] = corners_3d[0, :] + obj.t[0]\n",
    "    corners_3d[1, :] = corners_3d[1, :] + obj.t[1]\n",
    "    corners_3d[2, :] = corners_3d[2, :] + obj.t[2]\n",
    "\n",
    "    # project the 3d bounding box into the image plane\n",
    "    corners_2d = project_to_image(np.transpose(corners_3d), P)\n",
    "    # print 'corners_2d: ', corners_2d\n",
    "    return corners_2d, np.transpose(corners_3d)\n",
    "\n",
    "def rotx(t):\n",
    "    \"\"\" 3D Rotation about the x-axis. \"\"\"\n",
    "    c = np.cos(t)\n",
    "    s = np.sin(t)\n",
    "    return np.array([[1, 0, 0], [0, c, -s], [0, s, c]])\n",
    "\n",
    "\n",
    "def roty(t):\n",
    "    \"\"\" Rotation about the y-axis. \"\"\"\n",
    "    c = np.cos(t)\n",
    "    s = np.sin(t)\n",
    "    return np.array([[c, 0, s], [0, 1, 0], [-s, 0, c]])\n",
    "\n",
    "\n",
    "def rotz(t):\n",
    "    \"\"\" Rotation about the z-axis. \"\"\"\n",
    "    c = np.cos(t)\n",
    "    s = np.sin(t)\n",
    "    return np.array([[c, -s, 0], [s, c, 0], [0, 0, 1]])\n",
    "\n",
    "def project_to_image(pts_3d, P):\n",
    "    \"\"\" Project 3d points to image plane.\n",
    "\n",
    "    Usage: pts_2d = projectToImage(pts_3d, P)\n",
    "      input: pts_3d: nx3 matrix\n",
    "             P:      3x4 projection matrix\n",
    "      output: pts_2d: nx2 matrix\n",
    "\n",
    "      P(3x4) dot pts_3d_extended(4xn) = projected_pts_2d(3xn)\n",
    "      => normalize projected_pts_2d(2xn)\n",
    "\n",
    "      <=> pts_3d_extended(nx4) dot P'(4x3) = projected_pts_2d(nx3)\n",
    "          => normalize projected_pts_2d(nx2)\n",
    "    \"\"\"\n",
    "    n = pts_3d.shape[0]\n",
    "    pts_3d_extend = np.hstack((pts_3d, np.ones((n, 1))))\n",
    "    # print(('pts_3d_extend shape: ', pts_3d_extend.shape)) \n",
    "    pts_2d = np.dot(pts_3d_extend, np.transpose(P))  # nx3\n",
    "    pts_2d[:, 0] /= pts_2d[:, 2]\n",
    "    pts_2d[:, 1] /= pts_2d[:, 2]\n",
    "    return pts_2d[:, 0:2]\n",
    "\n",
    "def read_label(label_filename):\n",
    "    lines = [line.rstrip() for line in open(label_filename)]\n",
    "    objects = [Object3d(line) for line in lines]\n",
    "    return objects\n",
    "\n",
    "def inverse_rigid_trans(Tr):\n",
    "    \"\"\" Inverse a rigid body transform matrix (3x4 as [R|t])\n",
    "        [R'|-R't; 0|1]\n",
    "    \"\"\"\n",
    "    inv_Tr = np.zeros_like(Tr)  # 3x4\n",
    "    inv_Tr[0:3, 0:3] = np.transpose(Tr[0:3, 0:3])\n",
    "    inv_Tr[0:3, 3] = np.dot(-np.transpose(Tr[0:3, 0:3]), Tr[0:3, 3])\n",
    "    return inv_Tr\n",
    "\n",
    "def get_distance_for_object(object3d):\n",
    "    return math.sqrt(object3d.t[0]**2 + object3d.t[1]**2 + object3d.t[2]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(label_2_dir)\n",
    "dataset = []\n",
    "                   \n",
    "for file in files:\n",
    "    if not file.endswith(\".txt\"):\n",
    "        continue\n",
    "    \n",
    "    file_without_extension = os.path.splitext(file)[0]\n",
    "    left_objects = read_label(os.path.join(label_2_dir, file))     \n",
    "    calib = Calibration(os.path.join(calib_dir, file))\n",
    "    \n",
    "    right_objects = []\n",
    "    for left_object in left_objects:\n",
    "        if left_object.type == \"DontCare\":\n",
    "            continue\n",
    "        \n",
    "        dataset_row = np.zeros(9)\n",
    "        \n",
    "        box3d_left = compute_box_3d(left_object, calib.P)   \n",
    "        left_object.xmin = min(box3d_left[0], key=lambda t: t[0])[0]\n",
    "        left_object.xmax = max(box3d_left[0], key=lambda t: t[0])[0]\n",
    "        left_object.ymin = min(box3d_left[0], key=lambda t: t[1])[1]\n",
    "        left_object.ymax = max(box3d_left[0], key=lambda t: t[1])[1]\n",
    "        dataset_row[0] = (left_object.xmin + left_object.xmax) / 2\n",
    "        dataset_row[1] = (left_object.ymin + left_object.ymax) / 2\n",
    "        dataset_row[2] = left_object.xmax - left_object.xmin\n",
    "        dataset_row[3] = left_object.ymax - left_object.ymin\n",
    "        \n",
    "        box3d_right = compute_box_3d(left_object, calib.P3)      \n",
    "        right_object = copy(left_object)\n",
    "        right_object.xmin = min(box3d_right[0], key=lambda t: t[0])[0]\n",
    "        right_object.xmax = max(box3d_right[0], key=lambda t: t[0])[0]\n",
    "        right_object.ymin = min(box3d_right[0], key=lambda t: t[1])[1]\n",
    "        right_object.ymax = max(box3d_right[0], key=lambda t: t[1])[1]\n",
    "        dataset_row[4] = dataset_row[0] - ((right_object.xmin + right_object.xmax) / 2)\n",
    "        dataset_row[5] = dataset_row[1] - ((right_object.ymin + right_object.ymax) / 2)\n",
    "        dataset_row[6] = dataset_row[2] - (right_object.xmax - right_object.xmin)\n",
    "        dataset_row[7] = dataset_row[3] - (right_object.ymax - right_object.ymin)\n",
    "        \n",
    "        dataset_row[8] = get_distance_for_object(left_object)\n",
    "        \n",
    "        dataset.append(np.asarray(dataset_row))\n",
    "    \n",
    "dataset = np.array(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "dataset_x_train,dataset_x_test,dataset_y_train,dataset_y_test = train_test_split(dataset[:, :8],dataset[:, 8],test_size = 0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30427 samples, validate on 10143 samples\n",
      "Epoch 1/100\n",
      "30427/30427 [==============================] - 2s 73us/step - loss: 547.5546 - val_loss: 25.6982\n",
      "Epoch 2/100\n",
      "30427/30427 [==============================] - 2s 69us/step - loss: 21.6917 - val_loss: 19.4494\n",
      "Epoch 3/100\n",
      "30427/30427 [==============================] - 2s 68us/step - loss: 5722.1555 - val_loss: 19.8503\n",
      "Epoch 4/100\n",
      "30427/30427 [==============================] - 2s 68us/step - loss: 1448.2731 - val_loss: 22.3263\n",
      "Epoch 5/100\n",
      "30427/30427 [==============================] - 2s 69us/step - loss: 389.9367 - val_loss: 21.6911\n",
      "Epoch 6/100\n",
      "30427/30427 [==============================] - 2s 68us/step - loss: 69.6141 - val_loss: 21.8225\n",
      "Epoch 7/100\n",
      "30427/30427 [==============================] - 2s 68us/step - loss: 226.7483 - val_loss: 18.5799\n",
      "Epoch 8/100\n",
      "30427/30427 [==============================] - 2s 68us/step - loss: 27.8496 - val_loss: 18.1414\n",
      "Epoch 9/100\n",
      "30427/30427 [==============================] - 2s 68us/step - loss: 17.6905 - val_loss: 17.5717\n",
      "Epoch 10/100\n",
      "30427/30427 [==============================] - 2s 67us/step - loss: 17.2219 - val_loss: 17.1226\n",
      "Epoch 11/100\n",
      "30427/30427 [==============================] - 2s 68us/step - loss: 16.8690 - val_loss: 16.6714\n",
      "Epoch 12/100\n",
      "30427/30427 [==============================] - 2s 68us/step - loss: 16.5203 - val_loss: 16.3691\n",
      "Epoch 13/100\n",
      "30427/30427 [==============================] - 2s 68us/step - loss: 16.1547 - val_loss: 16.0008\n",
      "Epoch 14/100\n",
      "30427/30427 [==============================] - 2s 70us/step - loss: 15.7800 - val_loss: 15.4449\n",
      "Epoch 15/100\n",
      "30427/30427 [==============================] - 2s 71us/step - loss: 15.3599 - val_loss: 15.0246\n",
      "Epoch 16/100\n",
      "30427/30427 [==============================] - 2s 69us/step - loss: 14.8552 - val_loss: 14.5952\n",
      "Epoch 17/100\n",
      "30427/30427 [==============================] - 2s 68us/step - loss: 15.2174 - val_loss: 14.4312\n",
      "Epoch 18/100\n",
      "30427/30427 [==============================] - 2s 68us/step - loss: 14.4247 - val_loss: 14.2338\n",
      "Epoch 19/100\n",
      "30427/30427 [==============================] - 2s 67us/step - loss: 14.1777 - val_loss: 13.8269\n",
      "Epoch 20/100\n",
      "30427/30427 [==============================] - 2s 67us/step - loss: 13.8463 - val_loss: 13.5137\n",
      "Epoch 21/100\n",
      "30427/30427 [==============================] - 2s 67us/step - loss: 13.4965 - val_loss: 13.1067\n",
      "Epoch 22/100\n",
      "30427/30427 [==============================] - 2s 69us/step - loss: 13.0269 - val_loss: 12.7315\n",
      "Epoch 23/100\n",
      "30427/30427 [==============================] - 2s 68us/step - loss: 12.3112 - val_loss: 12.0488\n",
      "Epoch 24/100\n",
      "30427/30427 [==============================] - 2s 68us/step - loss: 503.9287 - val_loss: 11.7343\n",
      "Epoch 25/100\n",
      "30427/30427 [==============================] - 2s 68us/step - loss: 11.4658 - val_loss: 11.1345\n",
      "Epoch 26/100\n",
      "30427/30427 [==============================] - 2s 67us/step - loss: 11.1557 - val_loss: 10.8713\n",
      "Epoch 27/100\n",
      "30427/30427 [==============================] - 2s 67us/step - loss: 10.9695 - val_loss: 10.6796\n",
      "Epoch 28/100\n",
      "30427/30427 [==============================] - 2s 67us/step - loss: 10.8380 - val_loss: 10.6043\n",
      "Epoch 29/100\n",
      "30427/30427 [==============================] - 2s 66us/step - loss: 10.6702 - val_loss: 11.0251\n",
      "Epoch 30/100\n",
      "30427/30427 [==============================] - 2s 67us/step - loss: 10.5659 - val_loss: 10.1904\n",
      "Epoch 31/100\n",
      "30427/30427 [==============================] - 2s 68us/step - loss: 10.3019 - val_loss: 10.8526\n",
      "Epoch 32/100\n",
      "30427/30427 [==============================] - 2s 67us/step - loss: 10.1023 - val_loss: 9.7515\n",
      "Epoch 33/100\n",
      "30427/30427 [==============================] - 2s 67us/step - loss: 9.8169 - val_loss: 9.3568\n",
      "Epoch 34/100\n",
      "30427/30427 [==============================] - 2s 69us/step - loss: 9.3838 - val_loss: 9.0470\n",
      "Epoch 35/100\n",
      "30427/30427 [==============================] - 2s 68us/step - loss: 9.1834 - val_loss: 8.7967\n",
      "Epoch 36/100\n",
      "29120/30427 [===========================>..] - ETA: 0s - loss: 9.0722"
     ]
    }
   ],
   "source": [
    "\n",
    "#Dependencies\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "keras.backend.clear_session()\n",
    "if 'model' in locals():\n",
    "  del model\n",
    "\n",
    "# Neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=8, activation=\"relu\"))\n",
    "model.add(Dense(4, activation=\"relu\"))\n",
    "model.add(Dense(4, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"linear\"))\n",
    "opt = Adam(lr=1e-3)\n",
    "model.compile(loss=\"mean_absolute_percentage_error\", optimizer=opt)\n",
    "model.fit(dataset_x_train, dataset_y_train, validation_data=(dataset_x_test, dataset_y_test), epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] mean: 3.78%, std: 5.08%\n",
      "[INFO] mean squared error:  3.1152559987627986\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(dataset_x_test)\n",
    "diff = preds.flatten() - dataset_y_test\n",
    "percentDiff = (diff / dataset_y_test) * 100 \n",
    "absPercentDiff = np.abs(percentDiff)\n",
    "mean = np.mean(absPercentDiff)\n",
    "std = np.std(absPercentDiff)\n",
    "\n",
    "print(\"[INFO] mean: {:.2f}%, std: {:.2f}%\".format(mean, std))\n",
    "print(\"[INFO] mean squared error: \", mean_squared_error(dataset_y_test, preds.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "errors = np.abs(diff)\n",
    "distances = dataset_y_test\n",
    "plt.scatter(errors, distances)\n",
    "pfit = np.polyfit(errors, distances, 1)\n",
    "trend_line_model = np.poly1d(pfit)\n",
    "\n",
    "plt.plot(errors, trend_line_model(errors), \"m--\")\n",
    "plt.axis([0,30,0,150])\n",
    "plt.ylabel('Distance(meters)')\n",
    "plt.xlabel('Error amount(meters)')\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"model-good.h5\")\n",
    "opt = Adam(lr=1e-3)\n",
    "model.compile(loss=\"mean_absolute_percentage_error\", optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
